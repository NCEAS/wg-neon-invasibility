---
title: "Merge_VegBank_data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Impo

```{r}

library(readr)
library(readxl)
library(here)
library(tidyverse)
library(knitr)

# Paths to data
shared_data_dir <- "/home/shares/neon-inv"
data_raw <- file.path(shared_data_dir, "raw_VegBank_data")
data_output <- file.path(shared_data_dir, "output_files")

VegBank_AK_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_AK_KPEACH_reduced.csv"))

VegBank_AL_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_AL_KPEACH_reduced.csv"))

VegBank_FL_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_FL_KPEACH_reduced.csv"))

VegBank_GA_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_GA_KPEACH_reduced.csv"))

VegBank_MS_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_MS_KPEACH_reduced.csv"))

VegBank_NC_coastal_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_NC_coastal_KPEACH_reduced.csv"))

VegBank_NC_fringe_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_NC_fringe_KPEACH_reduced.csv"))

VegBank_NCMts_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_NCMts_KPEACH_reduced.csv"))

VegBank_NCPP_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_NCPP_KPEACH_reduced.csv"))

VegBank_Proj129_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_Proj129_KPEACH_reduced.csv"))

VegBank_SC_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_SC_KPEACH_reduced.csv"))

VegBank_TN_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_TN_KPEACH_reduced.csv"))

VegBank_TX_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_TX_KPEACH_reduced.csv"))

VegBank_VA_KPEACH_reduced  <- read_csv(file.path(data_output, "VegBank_VA_KPEACH_reduced.csv"))

NCVS_WV_EB_reduced <- read_csv(file.path(data_output, "NCVS_WV_KPEACH_EB_reduced.csv"))


```


```{r}


df1 <-  merge(VegBank_AK_KPEACH_reduced, VegBank_AL_KPEACH_reduced, all = TRUE)

df2 <-  merge(df1, VegBank_FL_KPEACH_reduced, all = TRUE)

df3 <-  merge(df2, VegBank_GA_KPEACH_reduced, all = TRUE)

df4 <-  merge(df3, VegBank_MS_KPEACH_reduced, all = TRUE)

df5 <-  merge(df4, VegBank_NC_coastal_KPEACH_reduced, all = TRUE)

df6 <-  merge(df5, VegBank_NC_fringe_KPEACH_reduced, all = TRUE)

df7 <-  merge(df6, VegBank_NCMts_KPEACH_reduced, all = TRUE)

df8 <-  merge(df7, VegBank_NCPP_KPEACH_reduced, all = TRUE)

df9 <-  merge(df8, VegBank_Proj129_KPEACH_reduced, all = TRUE)

df10 <-  merge(df9, VegBank_SC_KPEACH_reduced, all = TRUE)

df11 <-  merge(df10, VegBank_TN_KPEACH_reduced, all = TRUE)

df12 <-  merge(df11, VegBank_TX_KPEACH_reduced, all = TRUE)

df13 <- merge(df12, VegBank_VA_KPEACH_reduced, all=TRUE)
glimpse(df13)
# clean up to match other datasets
df13 <- df13 %>% rename(ExoticStatus = NEW_ExoticStatus, GrowthForm = NEW_GrowthForm) %>%
  mutate(UniqueID = paste(Dataset, VegBankUniqueID, sep="_"))

All_VegBank_KPEACH_reduced <-  merge(df13, NCVS_WV_EB_reduced, all = TRUE)
glimpse(All_VegBank_KPEACH_reduced)


```

Quality Checks - fixing duplicate rows

```{r}

All_VegBank_KPEACH_reduced  <- unique(All_VegBank_KPEACH_reduced)

#unique(All_VegBank_KPEACH_031621$previousObsCode)
#No rows have a previous observation code so removing this column
All_VegBank_KPEACH_reduced <- All_VegBank_KPEACH_reduced %>% select(-'previousObsCode')

#Looking for duplicate rows. It looks like there are some semi-duplicate rows in the final merged data table (aka rows with the same SpCode and VegBankUniqueID but unique cover values). It looks like those came from 1 of 2 sources: 1. The data came with them. Someone accidentally input two rows for the same species with two different cover values. OR 2. When I renamed certain species it made two rows look like semi-duplicates. For example, a researcher may record a .5 cover value for  _Verbascum thapsus ssp. thapsus_ and a .3 cover value for  _Verbascum thapsus_ in the same plot and the same year. But _Verbascum thapsus_ does not have any subspecies according to USDA so I reduced _Verbascum thapsus ssp. thapsus_ to _Verbascum thapsus_ manually. Then those two rows would appear identical except for the cover value. 
duplicates <- All_VegBank_KPEACH_reduced %>% group_by(Dataset, UniqueID, SpCode) %>% summarise(n_obs = n()) %>% filter(n_obs > 1)
table(duplicates$Dataset) # not that many
# look at an example
All_VegBank_KPEACH_reduced %>% filter(Dataset=="NCVS_WV", SpCode=="ASTER", UniqueID=="SHMO.9") # family ID'd
All_VegBank_KPEACH_reduced %>% filter(UniqueID=="VEGBANK_NC_Coastal_057-09-0825", SpCode=="SCHIZ4") # probably multiple species of the same genus

# concerning if the pctcov measurements are the same, but if not I think we condense (ssp, genus, stuff like that)
duplicates = duplicates %>% mutate(check = paste(UniqueID, SpCode, sep=","))
check = All_VegBank_KPEACH_reduced %>% mutate(check = paste(UniqueID, SpCode, sep=",")) %>%
  filter(check %in% duplicates$check)

# looks like most are issues with varieties/subspecies reduced to same code, and missing info in woodiness column
# reduce to one measure of cover per species per plot
All_VegBank_KPEACH_reduced2 = All_VegBank_KPEACH_reduced %>% select(-Woodiness) %>% ungroup() %>% group_by(Dataset, Zone, Year, Lat, Long, `Taxon Observation Area`, bestname, SpCode, ExoticStatus, ExoticStatus_Origin, Duration, GrowthForm, UniqueID, VegBankUniqueID, `Public Latitude`, `Public Longitude`, `Sampling Level`) %>%
  summarise(PctCov = sum(PctCov)) # reduced about 200 rows

duplicates <- All_VegBank_KPEACH_reduced2 %>% ungroup() %>% group_by(Dataset, UniqueID, SpCode) %>% summarise(n_obs = n()) %>% filter(n_obs > 1)
table(duplicates$Dataset) # reduced most
duplicates = duplicates %>% mutate(check = paste(UniqueID, SpCode, sep=","))
check = All_VegBank_KPEACH_reduced2 %>% mutate(check = paste(UniqueID, SpCode, sep=",")) %>%
  filter(check %in% duplicates$check)

# remaining duplicates are issues with bestname including not all bestnames...'
# hard to tell if these are duplicates or distinct cover measurements
# checked for SC - they seem like distinct cover measurements... safe to condense
check_new = check %>% ungroup() %>% group_by(Dataset, Zone, Year, Lat, Long, `Taxon Observation Area`, SpCode, ExoticStatus, ExoticStatus_Origin, Duration, GrowthForm, UniqueID, VegBankUniqueID, `Public Latitude`, `Public Longitude`, `Sampling Level`) %>% summarise(PctCov = sum(PctCov))

# join actual bestname to code
codes <- read_csv("/home/shares/neon-inv/output_files/USDA_Plants_ScientificNames.csv")
codes = codes %>% select(Accepted.Symbol, Scientific.Name) %>% rename(SpCode=Accepted.Symbol, bestname=Scientific.Name) %>% distinct()
codes = codes[!duplicated(codes$SpCode),]
check_new = check_new %>% left_join(codes) %>% mutate(check = paste(UniqueID, SpCode, sep=","))

# drop old rows and add innew
All_VegBank_KPEACH_reduced3 = All_VegBank_KPEACH_reduced2 %>% mutate(check = paste(UniqueID,SpCode, sep=",")) %>%
  filter(!check %in% check_new$check)
All_VegBank_KPEACH_reduced3 = rbind(All_VegBank_KPEACH_reduced3, check_new)

```

Check other columns
```{r}

year_NAs <- All_VegBank_KPEACH_reduced3[is.na(All_VegBank_KPEACH_reduced3$Year),]

#looking for any unexpected values
unique(All_VegBank_KPEACH_reduced3$`Sampling Level`) # Only 4's and 5's which is what we wanted to see

unique(All_VegBank_KPEACH_reduced3$Year) #No NAs or weird dates

unique(All_VegBank_KPEACH_reduced3$`Taxon Observation Area`) # NAs and 0s...?

#No NA taxon observation area
taxon_obs_area_NAs <- All_VegBank_KPEACH_reduced3[is.na(All_VegBank_KPEACH_reduced3$`Taxon Observation Area`),] # bunch missing from EV
table(taxon_obs_area_NAs$Dataset)  # all WV
taxon_obs_area_0s <- All_VegBank_KPEACH_reduced3 %>% filter(`Taxon Observation Area`==0) # all WV also
# y dimension of plot is 0...wonder if those are transects

# not sure if missing vals were dropped from other datasets, but I'm okay with leaving them in for now

#Whew. 0 NA rows for bestname
bestname_NAs <- All_VegBank_KPEACH_reduced3[is.na(All_VegBank_KPEACH_reduced3$bestname),]

#0 rows with no cover data
pct_cov_NAs <- All_VegBank_KPEACH_reduced3[is.na(All_VegBank_KPEACH_reduced3$PctCov),]


```

Check to make sure codes are for accepted symbols using Ian's taxonomy
```{r}
tax <- read_csv(file.path(data_raw, "taxonomy_temp10_revised.csv"))
glimpse(tax)
All_VegBank_KPEACH_reduced3 %>% filter(SpCode %in% tax$Synonym.Symbol) # none! that's good
# drop check column
All_VegBank_KPEACH_reduced3 = All_VegBank_KPEACH_reduced3 %>% select(-check)

```

Check to see that each species has one assigned exotic status

```{r}
All_VegBank_KPEACH_reduced3 %>% filter(SpCode=="DESMO")

check_exo = All_VegBank_KPEACH_reduced3 %>% ungroup() %>% select(SpCode, ExoticStatus) %>% group_by(SpCode) %>%
  distinct() %>% summarise(n_exo = n()) %>% filter(n_exo > 1)
# 12 need to be fixed...
# exmaple to see if we need to condense cover...?
All_VegBank_KPEACH_reduced3 %>% filter(SpCode=="AMBRO") # exotic status missing from WV but we have it for others.. could be an error on my end
All_VegBank_KPEACH_reduced3 %>% filter(SpCode=="AMST80") # also best names are not always consistent...

check_name = All_VegBank_KPEACH_reduced3 %>% ungroup() %>% select(SpCode, bestname) %>% group_by(SpCode) %>%
  distinct() %>% summarise(n_exo = n()) %>% filter(n_exo > 1)

## EVE PICK UP HERE
  # 12 species codes that don't have consistent exotic status
  # There are a ton of species codes that do not have the right bestname

```


Standardize merged data to match Ian's taxonomy 
```{r}
# clean up Ian's tax file
tax_unique = tax %>% select(Accepted.Symbol, Duration, GrowthForm, inv_L48, bestname) %>% rename(SpCode = Accepted.Symbol, ExoticStatus = inv_L48) %>% distinct()
# ID and remove empty rows (duplicates)
tax_unique = tax_unique[order(tax_unique[,1], tax_unique[,2]),]
tax_unique = tax_unique[!duplicated(tax_unique$SpCode),]

# join to data
All_VegBank_KPEACH_reduced4 = left_join(All_VegBank_KPEACH_reduced3 %>% ungroup() %>% select(-c(bestname, Duration, GrowthForm, ExoticStatus)), tax_unique, by="SpCode") # check rows match WV clean


```

Check which codes aren't in tax
```{r}
missing = All_VegBank_KPEACH_reduced4 %>% filter(!SpCode %in% tax_unique$SpCode)
unique(missing$SpCode) # most are nomatches, but some are lefit
# drop nomatch codes
missing_unique = missing[!grepl("NOMATCH", missing$SpCode),]
unique(missing_unique$SpCode) # these are codes that are not in Ian's taxonomoy
  
```

Make sure they are accepted symbols using USDA
```{r}
codes <- read_csv("/home/shares/neon-inv/output_files/USDA_Plants_ScientificNames.csv")
head(codes)
fix = data.frame(SpCode = unique(missing_unique$SpCode))
fix %>% filter(SpCode %in% codes$Synonym.Symbol) # none! should all be accepted symbols. that's good
fix %>% filter(!(SpCode %in% codes$Accepted.Symbol))
# fix FEBR7 in codes
codes$Accepted.Symbol[codes$Accepted.Symbol=="7-Feb"] <- "FEBR7"
# now all fix codes are in USDA

```
Pull missing codes from Kristen's key
```{r}
KPEACH_ExoticStatus_authority <- read_csv("/home/shares/neon-inv/output_files/KPEACH_ExoticStatus_authority_031621.csv")
glimpse(KPEACH_ExoticStatus_authority)

# make sure missing codes are in here
fix %>% filter(!(SpCode %in% KPEACH_ExoticStatus_authority$SpCode)) # yay! so all codes are correct

# pull just exotic status, duration, and growth form (we know there are issues with bestname)
KP_exo = KPEACH_ExoticStatus_authority %>% select(SpCode, NEW_ExoticStatus, ExoticStatus_Origin, USDA_Duration, USDA_Growth_Form) %>% distinct() %>% filter(SpCode %in% fix$SpCode)
# check to make sure there's only one entry per code
KP_exo %>% group_by(SpCode) %>% summarise(n_exo = n()) %>% filter(n_exo > 1)
# two duplicates
KP_exo %>% filter(SpCode=="AMAC4") # should be I
KP_exo %>% filter(SpCode=="RHBE2") # should be NA (not reported in L48)
# drop
KP_exo$NEW_ExoticStatus[KP_exo$SpCode=="AMAC4"] <- "I"
KP_exo$NEW_ExoticStatus[KP_exo$SpCode=="RHBE2"] <- NA
KP_exo = unique(KP_exo)

# join to fix
fix_join = left_join(fix, KP_exo)

```
Add bestname from USDA to fix key
```{r}
head(codes)
codes = codes %>% select(Accepted.Symbol, Scientific.Name) %>% rename(SpCode=Accepted.Symbol, bestname=Scientific.Name) %>% distinct()
codes = codes[!duplicated(codes$SpCode),]

fix_join = left_join(fix_join, codes)

```
Join back to AllVeg and clean up
```{r}
All_VegBank_KPEACH_reduced5 = left_join(All_VegBank_KPEACH_reduced4, fix_join, by="SpCode")
glimpse(All_VegBank_KPEACH_reduced5)

All_VegBank_KPEACH_reduced6 = All_VegBank_KPEACH_reduced5 %>% mutate(bestname = ifelse(is.na(bestname.y), bestname.x, bestname.y),Duration = ifelse(is.na(USDA_Duration), Duration, USDA_Duration),GrowthForm = ifelse(is.na(USDA_Growth_Form), GrowthForm, USDA_Growth_Form),ExoticStatus = ifelse(is.na(NEW_ExoticStatus), ExoticStatus, NEW_ExoticStatus),ExoticStatus_Origin = ifelse(is.na(ExoticStatus_Origin.y), ExoticStatus_Origin.x, ExoticStatus_Origin.y)) %>% select(-c(bestname.x, bestname.y,USDA_Duration, NEW_ExoticStatus, USDA_Growth_Form, ExoticStatus_Origin.x, ExoticStatus_Origin.y))

```

Check again to make sure all codes match to only one exotic status
```{r}
All_VegBank_KPEACH_reduced6 %>% select(SpCode, ExoticStatus) %>% distinct() %>% group_by(SpCode) %>% summarise(n_exo = n()) %>% filter(n_exo > 1) # YAY!
# Each code should only match to one exotic status
# check for bestname, duration and growthform just to be safe
All_VegBank_KPEACH_reduced6 %>% select(SpCode, bestname) %>% distinct() %>% group_by(SpCode) %>% summarise(n_exo = n()) %>% filter(n_exo > 1)
All_VegBank_KPEACH_reduced6 %>% select(SpCode, GrowthForm) %>% distinct() %>% group_by(SpCode) %>% summarise(n_exo = n()) %>% filter(n_exo > 1) # YAY!
All_VegBank_KPEACH_reduced6 %>% select(SpCode, Duration) %>% distinct() %>% group_by(SpCode) %>% summarise(n_exo = n()) %>% filter(n_exo > 1) # YAY!
# no duplicates!


```

Last check - make sure exotic status that was hand corrected by NCEAS people is included here
```{r}
hand_exo = read_csv(file.path(data_output, "multStatusSpL48 - multStatusSpL48.csv"))
head(hand_exo)

All_VegBank_KPEACH_reduced7 = All_VegBank_KPEACH_reduced6 %>% left_join(hand_exo %>% select(SpCode, 'FINAL DECISION (L48)'))
All_VegBank_KPEACH_reduced7 = All_VegBank_KPEACH_reduced7 %>% mutate(ExoticStatus = ifelse(is.na(`FINAL DECISION (L48)`), ExoticStatus, `FINAL DECISION (L48)`)) %>% select(-`FINAL DECISION (L48)`)
# check one that was NA and should now be I
All_VegBank_KPEACH_reduced7 %>% filter(SpCode=="BRIN2") # YAY!

```


Export

```{r}


  #As csv
write.csv(All_VegBank_KPEACH_reduced7,"/home/shares/neon-inv/output_files/All_VegBank_KPEACH_EB_reduced.csv", row.names = FALSE)

#write.csv(All_VegBank_KPEACH_reduced7,"All_VegBank_KPEACH_EB_reduced.csv", row.names = FALSE)


```

Some prelim exploration
```{r}
# How many plots in these added dataset?
n_distinct(All_VegBank_KPEACH_reduced7$UniqueID) # wow!
# How many invaded vs. uninvaded
All_VegBank_KPEACH_reduced7 %>% filter(ExoticStatus=="I") %>% select(UniqueID) %>% distinct(UniqueID) %>% nrow()
# Wow - most are invaded
# but this includes plots with multiple sampling years
# how many distinct locations?
all_plots = All_VegBank_KPEACH_reduced7 %>% ungroup() %>% select(Dataset, UniqueID, Long, Lat) %>% distinct() %>%
  filter(!is.na(Long))
# ~15,000
inv_plots = All_VegBank_KPEACH_reduced7 %>% ungroup() %>% filter(ExoticStatus=="I") %>% select(Dataset, UniqueID, Long, Lat) %>% distinct() %>%
  filter(!is.na(Long))
# ~5000

# map?
library(mapproj)
states <- map_data("state")
ggplot(states, aes(long, lat, group = group)) + 
  geom_polygon(fill = "white", colour = "black") + 
  geom_point(data = inv_plots, aes(Long, Lat), pch=16, size=2.5, alpha=0.2, 
             inherit.aes = FALSE) + coord_map("conic", lat0 = 30) + xlab("Longitude") + ylab("Latitude") +
  theme(axis.text=element_text(size=12), legend.text=element_text(size=12))

  

```
Where does this fill in for old datasets?
```{r}
all_nceas = read_csv(file.path("/home/beaury/Spatial Autocorrelation", "rawdatamodel_Mar16.csv"))
head(all_nceas)

all_plots = rbind(all_nceas %>% select(Dataset, UniqueID, Long, Lat), inv_plots)
all_plots = all_plots %>% mutate(Update = ifelse(Dataset %in% c("NPS", "BLM", "FIA", "NEON"), "oldata", "newdata"))


ggplot(states, aes(long, lat, group = group)) + 
  geom_polygon(fill = "white", colour = "black") + 
  geom_point(data = all_plots, aes(Long, Lat, color=Update), pch=16, size=1.5, alpha=0.2, 
             inherit.aes = FALSE) + coord_map("conic", lat0 = 30) + xlab("Longitude") + ylab("Latitude") +
  theme(axis.text=element_text(size=12), legend.text=element_text(size=12)) + ggtitle("Invaded plots across datasets (n = 31,211)")


```


